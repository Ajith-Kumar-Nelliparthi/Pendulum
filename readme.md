# â³ Pendulum-v1 Reinforcement Learning

Welcome to the Pendulum-v1 Reinforcement Learning Project! ğŸš€ This repository implements Q-learning to train an agent to balance a pendulum using discrete action space.

![pendulum](https://github.com/user-attachments/assets/39dc248a-be6a-45fe-b679-8a37fef3b39b)


## ğŸ¯ Project Overview

The Pendulum-v1 environment is a classic reinforcement learning problem where the goal is to keep a pendulum upright by applying torques. The project discretizes the continuous state and action space and applies Q-learning to optimize the control strategy.

## ğŸ— Features

âœ… Discretized State and Action Space â€“ Converts continuous observations into discrete bins for Q-learning.\
âœ… Epsilon-Greedy Exploration â€“ Implements exploration-exploitation trade-off.\
âœ… Reward Shaping â€“ Encourages better balancing by penalizing deviation.\
âœ… Video Recording â€“ Saves the best episode as a video.\
âœ… Pretrained Model Saving â€“ Stores and loads the best Q-table.

## ğŸ“‚ Repository Structure
```
Pendulum/
â”‚â”€â”€ main.py                  # Training and evaluation script
â”‚â”€â”€ pendulum_q_table.npy      # Saved Q-table
â”‚â”€â”€ Videos/ pendulum.png      # Stores successful episode
â”‚â”€â”€ requirements.txt         # Dependencies
â”‚â”€â”€ README.md                # Documentation
```

## ğŸ›  Setup and Installation

1ï¸âƒ£ Clone the Repository
```
  git clone https://github.com/Ajith-Kumar-Nelliparthi/Pendulum.git
  cd Pendulum
```

## 2ï¸âƒ£ Install Dependencies

Make sure you have Python 3.8+ installed.
```
  pip install -r requirements.txt
```
## ğŸš€ Training the Agent

Run the following command to start training the agent:
```
  python main.py
```

The script will train the agent for 20,000 episodes and store the best Q-table in pendulum_q_table.npy.

## ğŸ¥ Recording the Best Episode

The best-performing episode is saved as a video in the Videos/ directory after training.

## ğŸ† Testing the Trained Model

Once training is complete, you can test the model using:
```
  python main.py --test
```
This will load the saved Q-table and run the agent in a human-rendered environment.

## ğŸ“Š Performance Metrics

Best Score Tracking â€“ Keeps track of the highest reward achieved.

Epsilon Decay â€“ Improves learning by reducing exploration over time.

## ğŸ–¼ï¸ Simple Physical Pendulum

## ğŸ“œ References

[OpenAI Gym](https://gymnasium.farama.org/environments/classic_control/mountain_car/)

[Q-learning Algorithm](https://en.wikipedia.org/wiki/Q-learning)

## ğŸ¤ Contributing

Feel free to fork this repository and contribute with improvements!

## ğŸ“§ Contact

For any questions, reach out to: \

[![Twitter](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://x.com/Ajith532542840)\
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/nelliparthi-ajith-233803262)\
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](nelliparthi123@gmail.com)

## ğŸŒŸ If you like this project, give it a star! â­

















